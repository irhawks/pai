#!/usr/bin/env python

import flask
from flask import Flask
from flask import request
from flask_cors import CORS
from flask import Response

import requests

import logging
import re
import collections
import json
import random
import argparse
import datetime
import urlparse
import time

app = Flask(__name__)
cors = CORS(app, resources={r"/*": {"origins": "*"}})

logger = logging.getLogger(__name__)

def transform_env(obj):
    envs = []
    if obj is None:
        return envs

    for k, v in obj.items():
        envs.append({"name": str(k), "value": str(v) if v is not None else ""})
    return envs

# port is a map, key is label, value is comma seperated numbers
Resource = collections.namedtuple("Resource",
        ["cpu", "memoryMB", "shmMB", "gpu", "port"])

def int_or_none(val):
    if val is None:
        return None
    return int(val)

def parse_resource(obj):
    result = {}
    if obj is None:
        return Resource(None, None, None, None, None)

    # allocate port during parse
    if obj.get("portList") is not None and len(obj["portList"]) > 0:
        allocated = set()

        ports = {}

        for port in obj["portList"]:
            label = port["label"]
            val = []

            begin = port.get("beginAt")
            if begin is None or int(begin) < 1024:
                begin = 1024
            else:
                begin = int(begin)

            num = int(port["portNumber"])
            for _ in xrange(num):
                for _ in xrange(10): # try to allocate 10 times
                    v = random.randint(begin, 65535)
                    if v not in allocated:
                        val.append(v)
                        allocated.add(v)
                        break

            if len(val) != num:
                raise RuntimeError("can not satisfy port request")

            ports[label] = ",".join(map(str, val))

        result["port"] = ports

    return Resource(
            int_or_none(obj.get("cpuNumber")),
            int_or_none(obj.get("memoryMB")),
            int_or_none(obj.get("shmMB")),
            int_or_none(obj.get("gpuNumber")),
            result.get("port"))

Role = collections.namedtuple("Role",
        ["name", "task_num", "command", "resource", "envs",
            "min_failed_task_count", "succeeded_task_count"])

def gen_role_wide_envs(role_name, task_num, resource, min_failed_task_count, succeeded_task_count):
    envs = {
            "PAI_CURRENT_TASK_ROLE_NAME": role_name,

            # following env variables are legacy, will not support in the future version
            "PAI_CURRENT_TASK_ROLE_TASK_COUNT": task_num,
            "PAI_CURRENT_TASK_ROLE_CPU_COUNT": resource.cpu or "",
            "PAI_CURRENT_TASK_ROLE_MEM_MB": resource.memoryMB or "",
            "PAI_CURRENT_TASK_ROLE_SHM_MB": resource.shmMB or "",
            "PAI_CURRENT_TASK_ROLE_GPU_COUNT": resource.gpu or "",
            "PAI_CURRENT_TASK_ROLE_MIN_FAILED_TASK_COUNT": min_failed_task_count is None or "",
            "PAI_CURRENT_TASK_ROLE_MIN_SUCCEEDED_TASK_COUNT": succeeded_task_count is None or "",
            # ensure_http_ssh_port make sure only one http/ssh port allocated to http
            "PAI_CURRENT_CONTAINER_PORT": resource.port["http"],
            "PAI_CONTAINER_SSH_PORT": resource.port["ssh"],
            # PAI_CURRENT_TASK_ROLE_CURRENT_TASK_INDEX is generated by runtime
            }

    # legacy code, will be removed in future version
    if resource.port is not None:
        port_list = []
        for k, v in resource.port.items():
            port_list.append(k + ":" + v)
            envs["PAI_CONTAINER_HOST_%s_PORT_LIST" % k] = v

        envs["PAI_CONTAINER_HOST_PORT_LIST"] = ";".join(port_list)

    return transform_env(envs)

def parse_role(obj):
    role_name = transform_name(obj["name"])
    task_num = int(obj["taskNumber"])
    resource = parse_resource(obj)
    min_failed_task_count = obj.get("minFailedTaskCount")
    succeeded_task_count = obj.get("minSucceededTaskCount")

    envs = transform_env(obj.get("env"))
    envs.extend(gen_role_wide_envs(role_name, task_num, resource,
        min_failed_task_count, succeeded_task_count))

    return Role(
            role_name,
            task_num,
            str(obj["command"]),
            resource,
            envs,
            min_failed_task_count,
            succeeded_task_count)

def gen_init_container(user_cmd, k8s_api_server):
    return [{
        "name": "init",
        "imagePullPolicy": "Always",
        "image": g_runtime,
        "env": [{
            "name": "USER_CMD",
            "value": user_cmd
            }, {
            "name": "KUBE_APISERVER_ADDRESS",
            "value": k8s_api_server
            }],
        ""
        "volumeMounts": [
            {"mountPath": "/usr/local/pai", "name": "pai-vol" },
            {"mountPath": "/usr/local/pai/logs", "name": "host-log"}
            ]}]

def gen_resource(resource):
    result = {}

    if resource.cpu is not None:
        result["cpu"] = resource.cpu
    if resource.memoryMB is not None:
        result["memory"] = str(resource.memoryMB) + "Mi"
    if resource.gpu is not None:
        result["nvidia.com/gpu"] = resource.gpu
    # TODO ignore shmMB now
    return result

def gen_ports(ports):
    result = []
    if ports is None:
        return result

    for k, v in ports.items():
        for port in v.split(","):
            result.append({"containerPort": int(port)})
    return result

def gen_completion_policy(min_failed_task_count, succeeded_task_count):
    result = {}
    if min_failed_task_count is not None:
        result["minFailedTaskCount"] = int(min_failed_task_count)
    if succeeded_task_count is not None:
        result["minSucceededTaskCount"] = int(succeeded_task_count)
    return result

def get_current_date():
    n = datetime.datetime.now()
    return "%d%02d%02d_%02d%02d%02d" % (
            n.year, n.month, n.day, n.hour, n.minute, n.second)

def gen_task_role(job_name, image, role, k8s_api_server):
    return {
            "name": role.name,
            "taskNumber": role.task_num,
            "frameworkAttemptCompletionPolicy":
            gen_completion_policy(role.min_failed_task_count,
                role.succeeded_task_count)
            , "task": {
                "retryPolicy": {"fancyRetryPolicy": False},
                "pod": {
                    "metadata": {"labels": {"type": "kube-launcher-task"}},
                    "spec": {
                        "restartPolicy": "Never",
                        "imagePullSecrets": [{"name": "isregcred"}], # TODO hard code
                        "serviceAccountName": "frameworkbarrier",
                        "initContainers": gen_init_container(role.command, k8s_api_server),
                        "containers": [{
                            "name": "main",
                            "image": image,
                            "command": ["/usr/local/pai/run"],
                            "env": role.envs,
                            "resources": {"limits": gen_resource(role.resource)},
                            "volumeMounts": [
                                {"mountPath": "/usr/local/pai", "name": "pai-vol"},
                                {"mountPath": "/usr/local/pai/logs", "name": "host-log"}
                                ]
                            }],
                        "ports": gen_ports(role.resource.port),
                        "volumes": [
                            {"name": "pai-vol", "emptyDir": {}},
                            {"name": "host-log", "hostPath":
                                {"path": "/var/log/pai/job/" + job_name + "/" + get_current_date()}}
                            ],
                        "hostNetwork": True
                        }
                    }
                }
            }

def gen_task_roles(job_name, image, roles, k8s_api_server):
    result = []
    for role in roles:
        result.append(gen_task_role(job_name, image, role, k8s_api_server))

    return result

def gen_framework_spec(job_name, image, roles, k8s_api_server):
    return {
            "apiVersion": "frameworkcontroller.microsoft.com/v1",
            "kind": "Framework",
            "metadata": {"name": job_name},
            "spec": {
                "executionType": "Start",
                "retryPolicy": {"fancyRetryPolicy": False},
                "taskRoles": gen_task_roles(job_name, image, roles, k8s_api_server)
                }}

def gen_job_wide_envs(default_fs_uri, job_name, role_names, roles, data_dir, output_dir, code_dir):
    result = {
        "PAI_DEFAULT_FS_URI": default_fs_uri,
        "PAI_JOB_NAME": job_name,
        "PAI_TASK_ROLE_COUNT": len(role_names),
        "PAI_TASK_ROLE_LIST": ",".join(role_names),

        # following 3 variables is legacy variables, will not support in the future version
        "PAI_DATA_DIR": data_dir,
        "PAI_OUTPUT_DIR": output_dir,
        "PAI_CODE_DIR": code_dir,
        }

    for role in roles:
        result["PAI_TASK_ROLE_TASK_COUNT_%s" % role.name] = role.task_num
        result["PAI_MIN_FAILED_INSTANCE_%s" % role.name] = role.min_failed_task_count
        result["PAI_MIN_SUCCEEDED_INSTANCE_%s" % role.name] = role.succeeded_task_count
        resource = role.resource
        if resource is not None:
            result["PAI_RESOURCE_%s" % role.name] = \
                    "cpu_count:%s,memMB:%s,shmMB:%s,gpu_count:%s" % (
                            resource.cpu, resource.memoryMB, resource.shmMB, resource.gpu)

        if role.resource.port is not None:
            port_list = []
            for k, v in role.resource.port.items():
                for i in xrange(role.task_num):
                    result["PAI_PORT_LIST_%s_%d_%s" % (role.name, i, k)] = v

    return transform_env(result)


def transform_name(name):
    return str(re.sub(r"[-_/]", "", name.lower()))

def transform(obj, k8s_api_server, default_fs_uri):
    job_name = transform_name(obj["jobName"])

    # following 3 dirs are legacy field, will not support in future version
    data_dir = obj.get("dataDir")
    output_dir = obj.get("outputDir")
    code_dir = obj.get("codeDir")

    task_role_count = len(obj["taskRoles"])
    roles = []
    role_names = []

    for role in obj["taskRoles"]:
        parsed = parse_role(role)
        role_names.append(parsed.name)

        roles.append(parsed)

    job_wide_envs = gen_job_wide_envs(default_fs_uri, job_name, role_names, roles,
            data_dir, output_dir, code_dir)

    for role in roles:
        role.envs.extend(job_wide_envs)

    return gen_framework_spec(
            job_name,
            str(obj["image"]),
            roles,
            k8s_api_server)


# This is legacy code, should remove in the future version
def ensure_http_ssh_port(spec):
    """ make sure job has http/ssh port and number should be 1, other parts of code
    assumed this condition """
    for role in spec["taskRoles"]:
        if role.get("portList") is None:
            role["portList"] = [
                    {"label": "http", "beginAt": 0, "portNumber": 1},
                    {"label": "ssh", "beginAt": 0, "portNumber": 1}]
        else:
            has = {"http": False, "ssh": False}
            for port in role["portList"]:
                if port["label"] in has.keys():
                    port["portNumber"] = 1 # make sure it's 1
                    has[port["label"]] = True
            if not has["http"]:
                role["portList"].append(
                        {"label": "http", "beginAt": 0, "portNumber": 1})
            if not has["ssh"]:
                role["portList"].append(
                        {"label": "ssh", "beginAt": 0, "portNumber": 1})


# handler

crd_url = "/apis/frameworkcontroller.microsoft.com/v1/namespaces/default/frameworks"

@app.route("/api/v1/user/<username>/jobs/<job_name>", methods=["PUT"])
def create_job(username, job_name):
    # TODO ignore username and job_name argument for now
    spec = request.get_json()
    if spec is None:
        return "should provide job spec" # TODO better error handling

    ensure_http_ssh_port(spec)

    url = urlparse.urljoin(k8s_api_server, crd_url)

    framework = json.dumps(transform(spec, k8s_api_server, default_fs_uri))
    result = requests.post(url,
            headers=g_k8s_api_header,
            verify=g_ca_path,
            data=framework)

    # TODO error handling
    logger.debug("response from %s is %s", url, result)

    return json.dumps({"success":True}), 202, {"ContentType":"application/json"}


def convert_iso_date_to_timestamp(s):
    if s is None:
        return None

    d = datetime.datetime.strptime(s, "%Y-%m-%dT%H:%M:%SZ")
    return time.mktime(d.timetuple()) * 1000

def walk_json_field_safe(obj, *fields):
    """ for example a=[{"a": {"b": 2}}]
    walk_json_field_safe(a, 0, "a", "b") will get 2
    walk_json_field_safe(a, 0, "not_exist") will get None
    """
    try:
        for f in fields:
            obj = obj[f]
        return obj
    except:
        return None

# ref https://github.com/Microsoft/pai/blob/pai-0.9.y/src/webportal/src/app/job/job-view/job-view.component.js#L87-L109
# https://github.com/Microsoft/frameworkcontroller/blob/8adcef25f6b00f2c903cba9fb85e8c69d3a02d98/pkg/apis/frameworkcontroller/v1/types.go#L413-L480
def translate_job_state(state, exit_code):
    """ exit_code may be None """
    if state == "AttemptCreationPending":
        return "WAITING"
    elif state == "AttemptCreationRequested":
        return "WAITING"
    elif state == "AttemptPreparing":
        return "WAITING"
    elif state == "AttemptRunning":
        return "RUNNING"
    elif state == "AttemptDeletionPending":
        return "WAITING"
    elif state == "AttemptDeletionRequested":
        return "WAITING"
    elif state == "AttemptDeleting":
        return "WAITING"
    elif state == "AttemptCompleted":
        return "WAITING"
    elif state == "Completed":
        if exit_code == 0:
            return "SUCCEEDED"
        else:
            return "FAILED"
    else:
        return "UNKNOWN"

@app.route("/api/v1/jobs", methods=["GET"])
def list_jobs():
    url = urlparse.urljoin(k8s_api_server, crd_url)

    response = requests.get(url,
            headers=g_k8s_api_header,
            verify=g_ca_path).json()

    logger.debug("response of get is %s", response)

    result = []

    for framework in response["items"]:
        tmp = {}
        # TODO make sure following fields are filled correctly
        tmp["name"] = walk_json_field_safe(framework, "metadata", "name")
        tmp["retries"] = walk_json_field_safe(framework,
                "status", "retryPolicyStatus", "totalRetriedCount")
        tmp["createdTime"] = convert_iso_date_to_timestamp(
                walk_json_field_safe(framework, "status", "startTime"))
        tmp["username"] = "core" # TODO hardcode
        tmp["completedTime"] = convert_iso_date_to_timestamp(
                walk_json_field_safe(framework, "status", "completionTime"))
        execution_type = walk_json_field_safe(framework, "spec", "executionType")
        if execution_type is not None:
            tmp["executionType"] = execution_type.upper()
        else:
            tmp["executionType"] = "START" # TODO not sure if this is correct

        exit_code = walk_json_field_safe(framework, "status", "attemptStatus", "completionStatus", "code")

        tmp["state"] = translate_job_state(
                walk_json_field_safe(framework, "status", "state"), exit_code)

        tmp["subState"] = tmp["state"] # TODO not sure what substate means, but webportal do not use it anyway
        tmp["appExitCode"] = exit_code

        result.append(tmp)

    return flask.jsonify(result)

#        {
#        "appExitCode": null
#        "completedTime": null
#        "createdTime": 1552536264271
#        "executionType": "START"
#        "name": "pytorch-mnist1"
#        "retries": 0
#        "state": "RUNNING"
#        "subState": "APPLICATION_RUNNING"
#        "username": "admin"
#        "virtualCluster": "default"
#        }

@app.route("/", methods=["GET"])
def index():
    return """<span>Hello from rest-lite</span>"""


if __name__ == "__main__":
    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',
            level=logging.DEBUG)
    parser = argparse.ArgumentParser()
    parser.add_argument("--k8s_api", "-k", help="kubernetes api uri eg. http://10.151.40.133:8080", required=True)
    parser.add_argument("--fs_uri", "-u", help="default fs uri", required=True)
    parser.add_argument("--host", "-H", help="host to listen on", default="0.0.0.0")
    parser.add_argument("--port", "-p", help="port to listen on", type=int, default="5000")
    parser.add_argument("--runtime", "-r", help="runtime image", default= "xudifsd/kube-runtime")
    parser.add_argument("--debug", "-d", help="debug option on flask", type=bool, default="False")
    parser.add_argument("--ca", "-c", help="ca file path")
    parser.add_argument("--bearer", "-b", help="bearer token file path")
    args = parser.parse_args()

    global k8s_api_server
    global default_fs_uri
    global g_runtime
    global g_ca_path
    global g_k8s_api_header

    k8s_api_server = args.k8s_api
    default_fs_uri = args.fs_uri
    g_runtime = args.runtime

    g_ca_path = args.ca
    bearer_path = args.bearer
    if (g_ca_path is None and bearer_path is not None) or (g_ca_path is not None and bearer_path is None):
        log.warning("please provide bearer_path and ca_path at the same time or not")
    g_k8s_api_header = {"Content-Type": "application/json"}
    if bearer_path is not None:
        with open(bearer_path, "r") as bearer_file:
           bearer = bearer_file.read()
           g_k8s_api_header["Authorization"] = "Bearer {}".format(bearer)

    app.run(host=args.host, port=args.port, debug=True)
